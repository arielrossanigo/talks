{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reconocimiento de objetos en imágenes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ariel Rossanigo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quien soy?\n",
    "\n",
    "* Ariel Rossanigo\n",
    "* Profe de Inteligencia Artificial\n",
    "* Developer, Data Scientist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objetivos de la charla\n",
    "\n",
    "* Mostrar como podemos atacar este tipo de problemas\n",
    "* Que todos se vayan con una idea del pipeline y que hace cada paso\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "* Definición del problema\n",
    "* Código\n",
    "* Explicación de las distintas partes involucradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distintos tipos de problemas en CV\n",
    "\n",
    "#### Clasificación\n",
    "\n",
    "<img src=\"./imgs/mnist.jpg\" width=\"600\" align=\"middle\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distintos tipos de problemas en CV\n",
    "\n",
    "#### Clasificación: Algunas veces no es tan simple\n",
    "\n",
    "<img src=\"./imgs/dogs_vs_bread.jpg\" width=\"600\" align=\"middle\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Localización\n",
    "\n",
    "<img src=\"./imgs/cat_face_detector_result_01.jpg\" width=\"600\" align=\"middle\">\n",
    "\n",
    "https://www.pyimagesearch.com/2016/06/20/detecting-cats-in-images-with-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Detección de objetos\n",
    "\n",
    "<img src=\"./imgs/object_detection.png\" width=\"600\" align=\"middle\">\n",
    "\n",
    " https://arxiv.org/abs/1311.2524"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Segmentación\n",
    "\n",
    "<img src=\"./imgs/segmentation.png\" width=\"600\" align=\"middle\">\n",
    "\n",
    "https://arxiv.org/abs/1703.06870"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<em style=\"float: right;\">10</em>\n",
    "\n",
    "### Una solución *\"Out of the box\"*\n",
    "\n",
    "Google ofrece una serie de modelos implementados en ``TensorFlow``, entre ellos uno que permite detectar objetos.\n",
    "\n",
    "Se puede descargar desde acá:\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "\n",
    "Tiene un tutorial para usarlo *\"de fábrica\"*, y otro para para entrenar nuestro propio reconocedor de objetos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from object_detection_helpers import open_image, load_labels, visualize_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Bajamos el modelo y configuramos algunos paths\n",
    "\n",
    "El modelo se puede bajar desde \n",
    "\n",
    "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "base_path = 'object_detection'\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "PATH_TO_CKPT = os.path.join('object_detection', MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "\n",
    "# Leemos el modelo que bajamos de internet\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "# Leemos las clases con las que fue entrenado el modelo\n",
    "category_index = load_labels(os.path.join(base_path, 'data', 'mscoco_label_map.pbtxt'), 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Leemos algunas imágenes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATHS = [os.path.join('test_images', x) for x in os.listdir('test_images')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for image_path in TEST_IMAGE_PATHS:\n",
    "\n",
    "            image_np = open_image(image_path)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "             \n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "              [boxes, scores, classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "            visualize_image(image_np, boxes, classes, scores, category_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Datos en crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scores\n",
    "# visualize_image(image_np.copy(), boxes, classes, scores, category_index, min_score_thresh=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<em style=\"float: right;\">20</em>\n",
    "\n",
    "### Los bloques\n",
    "\n",
    "<div><img src=\"imgs/bloques.jpg\" width=\"400\" style=\"float: right;\"></div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Clasificador de imágenes</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Detector / proponedor de regiones</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redes neuronales\n",
    "\n",
    "<div><img src=\"imgs/neuron.jpeg\" width=\"400\" style=\"float: left; margin: 10px;\"></div>\n",
    "\n",
    "<div><img src=\"imgs/neural_network.jpg\" width=\"400\" style=\"float: right; margin: 10px;\"></div>\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n",
    "http://cs231n.github.io/neural-networks-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Redes neuronales: Noción básica de funcionamiento\n",
    "\n",
    "<div><img src=\"imgs/mnist_input.png\" width=\"400\" align=\"middle\" style=\" margin: 10px;\" ></div>\n",
    "\n",
    "\n",
    "https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from object_detection_helpers import get_mnist_demo, show_weights\n",
    "model, X, y = get_mnist_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    model.fit(X, y, epochs=1)\n",
    "    show_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Redes neuronales: Noción básica de funcionamiento\n",
    "\n",
    "<div><img src=\"imgs/mnist_multilayer.png\" width=\"500\" align=\"middle\" style=\"margin: 10px;\"></div>\n",
    "\n",
    "https://www.youtube.com/watch?v=aircAruvnKk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning\n",
    "\n",
    "*The hierarchy of concepts enables the computer to learn complicated concepts bybuilding them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason,we call this approach to AI deep learning.*\n",
    "\n",
    "\n",
    "**Goodfellow et al 2016**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<em style=\"float: right;\">30</em>\n",
    "\n",
    "### Convoluciones\n",
    "\n",
    "<div><img src=\"imgs/conv_explanation.jpg\" width=\"50%\" style=\"float: left;\"></div>\n",
    "\n",
    "https://developer.apple.com/library/content/documentation/Performance/Conceptual/vImage/ConvolutionOperations/ConvolutionOperations.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convoluciones\n",
    "\n",
    "\n",
    "<div><img src=\"imgs/applying_filter.gif\" width=\"80%\" style=\"float: left; margin: 10px;\"></div>\n",
    "\n",
    "https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convoluciones\n",
    "\n",
    "#### Parámetros más comunes\n",
    "\n",
    "* **filters:** cantidad de filtros\n",
    "* **kernel_size:** tamaño del kernel\n",
    "* **strides:** la cantidad de pasos que muevo el kernel\n",
    "* **padding:** agrega ceros en los bordes para mantener el tamaño original\n",
    "* **activation:** función de activación aplicada ``pixel a pixel``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pooling\n",
    "\n",
    "<div><img src=\"imgs/max_pooling.png\" width=\"50%\" style=\"float: left;\"></div>\n",
    "\n",
    "* reduce el tamaño de los filtros\n",
    "* brinda robustez \n",
    "* features *equivariantes*\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "http://textminingonline.com/dive-into-tensorflow-part-v-deep-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Redes neuronales\n",
    "\n",
    "<div><img src=\"imgs/neural_network_complete.png\" width=\"90%\" style=\"float: left;\"></div>\n",
    "\n",
    "https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/comment-page-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<em style=\"float: right;\">40</em>\n",
    "\n",
    "### Tenemos un clasificador, ¿y ahora qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sliding windows\n",
    "\n",
    "<div><img src=\"imgs/sliding_window.gif\" width=\"90%\" style=\"float: left; margin: 10px;\" ></div>\n",
    "\n",
    "https://matthewearl.github.io/2016/05/06/cnn-anpr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2014: R-CNN (Region Convolutional Neural Network)\n",
    "\n",
    "<div><img src=\"imgs/rcnn.png\" width=\"80%\" style=\"float: none; margin: 10px;\"  align=\"middle\" ></div>\n",
    "\n",
    "https://arxiv.org/abs/1311.2524\n",
    "\n",
    "1. Selective search para proponer regiones (~2000 por imagen)\n",
    "2. AlexNet -> SVM para clasificar\n",
    "3. Linear regression para mejorar el box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2015: Fast R-CNN\n",
    "\n",
    "<div><img src=\"imgs/fast_rcnn.png\" width=\"70%\" style=\"margin: 10px;\"  align=\"middle\" ></div>\n",
    "\n",
    "https://arxiv.org/abs/1504.08083"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2016: Faster R-CNN \n",
    "\n",
    "<div><img src=\"imgs/faster_rcnn.png\" height=\"60%\" style=\"margin: 10px;\"  align=\"middle\" ></div>\n",
    "\n",
    "https://arxiv.org/abs/1506.01497"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2016: SSD (Single Shot Detector)\n",
    "\n",
    "<div><img src=\"imgs/ssd.png\" width=\"90%\" style=\"margin: 10px;\"  align=\"middle\" ></div>\n",
    "\n",
    "https://arxiv.org/abs/1512.02325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<em style=\"float: right;\">50</em>\n",
    "\n",
    "### Resumen para atacar un problema\n",
    "\n",
    "* Probar solución *Out of the box*\n",
    "* Re-entrenar el modelo para que se ajuste a las clases del problema\n",
    "* Elegir el modelo en base a las necesidades de tiempo y precisión que tengamos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preguntas?\n",
    "\n",
    "<img src=\"imgs/man-qmark.jpg\" width=\"400\" align=\"middle\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gracias!\n",
    "\n",
    "Mis datos de contacto:\n",
    "\n",
    "<p><img src=\"imgs/gmail-1162901_960_720.png\" width=\"40\" style=\"float: left;\" align=\"middle\"> arielrossanigo@gmail.com</p>\n",
    "\n",
    "<p><img src=\"imgs/twitter-312464_960_720.png\" width=\"40\" style=\"float: left;\" align=\"middle\"> @arielrossanigo</p>\n",
    "\n",
    "<p><img src=\"imgs/github-154769__340.png\" width=\"40\" style=\"float: left;\" align=\"middle\"> https://github.com/arielrossanigo</p>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
